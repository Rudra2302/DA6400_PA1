{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gym_minigrid\n",
    "import numpy as np\n",
    "import wandb\n",
    "from gym_minigrid.wrappers import FullyObsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1efde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37017929",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {'method': 'random'}\n",
    "metric = {'name': 'reward',\n",
    "    'goal': 'maximize'}\n",
    "sweep_config['metric'] = metric\n",
    "parameters_dict = {\n",
    "    'learning_rate': {'values': [0.1, 0.05, 0.01, 0.2, 0.25]},\n",
    "    'epsilon': {'values': [0.1, 0.2, 0.3, 0.05, 0.01]}\n",
    "}\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"RL_PA1_GridWorld_SARSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_agent(image):\n",
    "    for x in range(image.shape[0]):\n",
    "        for y in range(image.shape[1]):\n",
    "            if image[x, y, 0] == 10:\n",
    "                return (x, y)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b85f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(q_table, state, epsilon, env):\n",
    "    if np.random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return np.argmax(q_table[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a356aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(config=None):\n",
    "    env = gym.make(\"MiniGrid-Dynamic-Obstacles-5x5-v0\")\n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    env = FullyObsWrapper(env)\n",
    "    \n",
    "    with wandb.init():\n",
    "        config = wandb.config\n",
    "        learning_rate = config.learning_rate\n",
    "        epsilon = config.epsilon\n",
    "        state_space_size = (5, 5, 4)\n",
    "        q_table = np.random.uniform(low=-2, high=0, size=(state_space_size + (env.action_space.n,)))\n",
    "        episodes = 10000\n",
    "        discount = 0.99\n",
    "\n",
    "        for ep in range(episodes):\n",
    "            done = False\n",
    "            obs, _ = env.reset()\n",
    "            step_count = 0\n",
    "            total_reward = 0\n",
    "\n",
    "            agent_pos = find_agent(obs[\"image\"])\n",
    "            agent_dir = obs['direction']\n",
    "            state = (agent_pos[0], agent_pos[1], agent_dir)\n",
    "            action = epsilon_greedy(q_table, state, epsilon, env)\n",
    "\n",
    "            while not done:\n",
    "                new_obs, _, done, _, _ = env.step(action)\n",
    "                step_count += 1\n",
    "\n",
    "                reward = 1 - 0.9 * (step_count / 100)\n",
    "                if done and reward <= 0:\n",
    "                    reward -= 1\n",
    "                total_reward += reward\n",
    "\n",
    "                new_agent_pos = find_agent(new_obs[\"image\"])\n",
    "                new_agent_dir = new_obs['direction']\n",
    "                new_state = (new_agent_pos[0], new_agent_pos[1], new_agent_dir)\n",
    "\n",
    "                new_action = epsilon_greedy(q_table, new_state, epsilon, env) if not done else None\n",
    "\n",
    "                current_q = q_table[state + (action, )]\n",
    "                future_q = q_table[new_state + (new_action, )] if not done else 0\n",
    "                new_q = (1 - learning_rate) * current_q + learning_rate * (reward + discount * future_q)\n",
    "                q_table[state + (action, )] = new_q\n",
    "\n",
    "                state, action = new_state, new_action\n",
    "                wandb.log({'reward': total_reward, 'episode': ep})\n",
    "                wandb.log({'length': step_count, 'episode': ep})\n",
    "\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, sarsa, count=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
